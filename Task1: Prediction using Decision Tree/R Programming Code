# Descision Tree Model
"""A decision tree is a model that represents decisions as branches of a tree,
with each branch representing an attribute or decision, 
and the final nodes representing outcomes or predictions.

Decision tree is a type of supervised machine learning algorithm. 
that is mostly used in classification problems 
and works for both categorical and continuous Input and output variables.

They work well for data with high dimensionality, 
and they can handle both categorical and numerical data.

"""
#Installing Packages
install.packages("party") 
install.packages("caret")

#Import Libraries
library(party)
library(caret)
library(rpart)
library(rpart.plot)
library(ggplot2)

# Dataset
data(iris)
str(iris)
head(iris)
summary(iris)


#Building the classifier
# Spliting the dataset into trainset and testset
set.seed(555)
indexes = createDataPartition(iris$Species, p = .8, list = F)
train = iris[indexes, ]
test = iris[-indexes, ]

#Model
''' Ctree - Conditional Inference Tree''' 

dt_classifer = ctree(formula=Species~., data = train)
print(dt_classifer)

# Graphical Representation
plot(dt_classifer)

# Predicting a value
iris[66,]
prediction_single <- predict(dt_classifer, newdata = test[66,])
prediction_single

# Understanding the splits
scatterplot1=ggplot(data = iris, aes(x=Petal.Length,y=Petal.Width,colour=Species))+
  geom_point(size = 4,shape=18)+
  theme_classic()+
  ggtitle("Scatter Plot")+
  theme(plot.title = element_text(hjust = 0.5,size = 20),
        legend.title = element_blank(),legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),axis.text = element_text(size = 15));
scatterplot1

plot_scatter=ggplot(data = iris, aes(x=Petal.Length,y=Petal.Width,colour=Species))+
  geom_point(size = 4,shape=18)+
  geom_vline(xintercept = 2.5,colour="orange",linewidth = 1,)+
  theme_classic()+
  ggtitle("Scatter Plot")+
  theme(plot.title = element_text(hjust = 0.5,size = 20),
        legend.title = element_blank(),legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),axis.text = element_text(size = 15))+
  geom_segment(aes(x = 2.5, y = 1.8,xend = 7,yend = 1.8),colour="orange",linewidth=1);plot_scatter

#Confusion Matrix
cm = confusionMatrix(test$Species, pred)
print(cm)

# Accuracy
accuracy = data.frame("Training Data"=cm$overall["Accuracy"],
                 "Testing Data"=cm$overall["Accuracy"]);accuracy

```


# Using rpart

#Create training and test datasets - 

set.seed(46465)

split=sample(nrow(iris),0.7*nrow(iris))          

training_data = iris[split,]
test_data = iris[-split,]

#Create a decision tree model - 
classifier = rpart(Species ~ . ,training_data, method = "class");classifier

#Visualization - 

plot_tree= prp(classifier,type=0,extra=4,main = "Decision Tree",tweak = 1.2,
               box.palette = list("pink","skyblue","thistle"),cex.main=2,yesno = 2,varlen = 0,
               faclen = 0,split.border.col ="black",branch.lwd = 2,legend.cex = 0.94,
               round = 2,nn.cex = 1.1,yesno.yshift = -1.4,split.lwd = 2,branch = 0.1)

#Predicting the class for an observation - 
set.seed(99432)
a=apply(iris[,-5],2,function(x) sample(seq(min(x),max(x),by=0.1),size=1))
d=data.frame(matrix(a,nrow=1,byrow = TRUE),check.names = FALSE)
names(d)=names(a);d

pr=predict(classifier,d,type="class");pr

#Confusion matrix - 
pred = predict(classifier, test_data[-5],type = "class")
cm_test = confusionMatrix(pred,test_data[,5]);cm_test

#1. Accuracy of the model for training data and test data:
pred2 = predict(classifier, training_data[-5],type = "class")
cm_train = confusionMatrix(pred2,training_data[,5]);cm_train

acc = data.frame("Training Data"=cm_train$overall["Accuracy"],
                 "Testing Data"=cm_test$overall["Accuracy"]);acc




#Conclusion - With 96% accuarcy the decision tree classifier can classify the data. 

```
